{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Constants import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "import LDS_model\n",
    "import utils\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "DEVICE = 'cuda:0'\n",
    "# torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDS_Analysis:\n",
    "    def __init__(self, model_name, em_iterations, T, d, M, L, scaling=True) -> None:\n",
    "        self.model_name = model_name\n",
    "        self.out_dir = f'{SHAPE_MODELS_DIR}/{self.model_name}_LDS_Analysis_L_{L}/'\n",
    "        if not os.path.exists(self.out_dir):\n",
    "            os.makedirs(self.out_dir)\n",
    "        self.particles_data = load_correspondences(shapes_desc_file=f'{PROJECT_DIR}/description.json', \n",
    "                                                correspondences_dir=f'{SHAPE_MODELS_DIR}/{self.model_name}_particles/',\n",
    "                                                T=T, d=d, M=M)\n",
    "        self.scaling_obj = MinMaxScaler()\n",
    "        if scaling:\n",
    "            self.scaled_particles_data = self.scaling_obj.fit_transform(self.particles_data.reshape(-1, self.particles_data.shape[-1])).reshape(self.particles_data.shape)\n",
    "        else:\n",
    "            self.scaled_particles_data = self.particles_data\n",
    "        self.lds_model = self.build_lds_model(em_iterations, T, d, M, L, True)\n",
    "    \n",
    "    def build_lds_model(self, em_iterations, T=25, d=3, M=256, L=32, plot_likelihood=True):\n",
    "        P = d * M\n",
    "        initial_A = utils.repeat(T-1, np.eye(L))\n",
    "        initial_W = utils.repeat(T, np.random.normal(0.0, 1.0, (P, L)))\n",
    "        lds = LDS_model.LDS(n_dim_obs=P, n_dim_state=L,\n",
    "                        transition_matrices = initial_A, \n",
    "                        observation_matrices = initial_W,\n",
    "                        em_vars=[\n",
    "                            'transition_matrices', 'observation_matrices',\n",
    "                            'transition_covariance', 'observation_covariance',\n",
    "                            'initial_state_mean', 'initial_state_covariance'\n",
    "                        ])\n",
    "        \n",
    "        loglikelihoods = np.zeros(em_iterations)\n",
    "        for i in range(len(loglikelihoods)):\n",
    "            start_em = timer()\n",
    "            print(f'-------Running EM iteration# {i} ----------')\n",
    "            particles_tensor = torch.from_numpy(self.scaled_particles_data).float().to(DEVICE)\n",
    "            particles_mask = np.zeros(self.particles_data.shape)\n",
    "            lds = lds.em(particles_tensor, n_iter=1, observations_mask=particles_mask)\n",
    "            end_em = timer()\n",
    "            print(f'^^EM Done in {(end_em - start_em)/60} minutes, Computing Log-Likelihood ^^')\n",
    "            start_log = timer()\n",
    "            loglikelihoods[i] = lds.loglikelihood(particles_tensor, observations_mask=particles_mask)\n",
    "            end_log = timer()\n",
    "            print(f'Iteration {i}, log-likelihood = {loglikelihoods[i]} computed in {(end_log - start_log)/60} minutes \\n\\n')\n",
    "        np.savetxt(f'{self.out_dir}/log_likelihood_{em_iterations}.txt', loglikelihoods)\n",
    "        if plot_likelihood:\n",
    "            plt.figure()\n",
    "            plt.plot(loglikelihoods)\n",
    "            plt.xlabel('EM Iteration')\n",
    "            plt.ylabel('Average Log Likelihood')\n",
    "            plt.savefig(f'{self.out_dir}/log_likelihood_{em_iterations}.png')\n",
    "        return lds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new model')\n",
    "analyze_cross_entropy_model = LDS_Analysis(model_name='pre_post_model_2500', em_iterations=100, T=25, d=3, M=256, L=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'pre_post_model_2500'\n",
    "particles_data = load_correspondences(shapes_desc_file=f'{PROJECT_DIR}/description.json', \n",
    "                                                correspondences_dir=f'{SHAPE_MODELS_DIR}/{model_name}_particles/',\n",
    "                                                T=25, d=3, M=256)\n",
    "particles_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = particles_data.reshape(-1, particles_data.shape[-1]).reshape(particles_data.shape)\n",
    "ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(particles_data.reshape(-1, particles_data.shape[-1])).reshape(particles_data.shape)\n",
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled = scaler.inverse_transform(scaled.reshape(-1, particles_data.shape[-1])).reshape(particles_data.shape)\n",
    "unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9abb8911c1aa7884fef042204dc94fda413b80958c53da6b047e0f4190aa0480"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('assignment': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
