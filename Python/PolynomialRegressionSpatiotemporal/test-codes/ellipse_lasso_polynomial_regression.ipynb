{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jadie Adams\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "font = {'size'   : 16}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "angles = np.arange(0, 2*np.pi, np.pi/4) + 0.5 # for 8 correspondences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a4a2a",
   "metadata": {},
   "source": [
    "# Ellipse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763cab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "N = 30 # number of samples\n",
    "d = 2 # dimension of correspondence points\n",
    "M = 8 # number of correspondence points\n",
    "L = 2 # dimension of latent space\n",
    "P = d*M  # dimension of observation space \n",
    "T = 8   # number of time points\n",
    "period = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: N - number of samples, T - number of time points\n",
    "Output: Generated data with shape (N, T, P) where P = dM (here d is 2 and M is 9)\n",
    "'''\n",
    "def generate_ellipse_data(N=3, T=16, period=8, x_radius_std=0.02, noise_std=0.02, plot=False):\n",
    "    # Major radius random value between 2 and 4 \n",
    "    # Minor radius varies between 1 and 3 on a sin wave dependent on t\n",
    "    data = []\n",
    "    if plot:\n",
    "        plt_x = []\n",
    "        plt_y = []\n",
    "    for sample_index in range(N):\n",
    "        data.append([])\n",
    "        major_radius = np.random.normal(0.6, x_radius_std)/3\n",
    "        # clip\n",
    "        if major_radius < 0:\n",
    "            major_radius = 0\n",
    "        if major_radius > 1:\n",
    "            major_radius =1\n",
    "        x_values = major_radius*np.cos(angles)\n",
    "        for i in range(T):\n",
    "            minor_diameter = 0.4*np.sin(i*(2*np.pi/period)) + 0.6 #between 1 and .2\n",
    "            minor_radius = minor_diameter/2\n",
    "            y_values = minor_radius*np.sin(angles)\n",
    "            data[sample_index].append([x_values,y_values])\n",
    "    data = np.asarray(data, np.float32)\n",
    "    # Add noise\n",
    "    data = data.reshape(N, T, 2*len(angles))\n",
    "    data = data + np.random.normal(0, noise_std, data.shape)\n",
    "    \n",
    "    if plot:\n",
    "        data2 = data.reshape(N, T, 2, len(angles))\n",
    "        plt_x = data2[:,:,0,:]\n",
    "        plt_y = data2[:,:,1,:]\n",
    "        plt.figure(figsize=(100, 30))\n",
    "        dim = math.ceil(T/8)\n",
    "        I = 3\n",
    "        J = min(16,len(plt_x[0]))\n",
    "        fig, axs = plt.subplots(I, J, figsize=(J,I+1))\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim([-0.5, 0.5])\n",
    "            ax.set_ylim([-0.5, 0.5])\n",
    "            ax.label_outer()\n",
    "        row = 0\n",
    "        colors = ['b', 'teal', 'g', 'y', 'orange', 'r', 'pink', 'm', 'c']\n",
    "        for i in range(I):\n",
    "            for j in range(J):\n",
    "                for p in range(len(plt_x[i][j])):\n",
    "                    axs[row][j].scatter(plt_x[i][j][p], plt_y[i][j][p], color=colors[p])\n",
    "                axs[0][j].set_title('t =' + str(j+1))\n",
    "            row += 1\n",
    "        plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88458382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "Z = generate_ellipse_data(N, T, period, plot=True)\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d21fdb",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39545451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "z = Z.reshape(N*T, d*M) # Shapes\n",
    "t = np.tile(np.arange(1,T+1), N) # Time points - explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eef657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get polynomial predictor vectors\n",
    "# TODO - rewrite without loops\n",
    "def get_predictors(degree, t):\n",
    "    X = np.zeros((len(t), degree))\n",
    "    for index in range(len(t)):\n",
    "        for deg in range(0,degree):\n",
    "            X[index][deg] = t[index]**(deg+1)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbade7b",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "To get optimal polynomial degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1132ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(1, T)\n",
    "\n",
    "test_mse = []\n",
    "for train_index, test_index in kf.split(t, z):\n",
    "    split_mse = []\n",
    "    train_t, train_z = t[train_index], z[train_index]\n",
    "    test_t, test_z = t[test_index], z[test_index]\n",
    "    for degree in degrees:\n",
    "        train_X = get_predictors(degree, train_t)\n",
    "        test_X = get_predictors(degree, test_t)\n",
    "        model = LinearRegression(normalize=True)\n",
    "        model.fit(train_X, train_z)\n",
    "        pred_test_z = model.predict(test_X)\n",
    "        mse = np.mean((pred_test_z - test_z)**2)\n",
    "        split_mse.append(mse)      \n",
    "    test_mse.append(split_mse)\n",
    "test_mse = np.mean(test_mse, axis=0)\n",
    "\n",
    "optimal_degree = np.argmin(test_mse)+1\n",
    "print(\"Optimal degree\", optimal_degree)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, test_mse)\n",
    "plt.xlabel(\"Degree of the polynome\")\n",
    "plt.ylabel(\"k-fold cross-validated mse\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ccf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(1, T)\n",
    "\n",
    "fig, axs = plt.subplots(len(degrees), 16, figsize=(32,len(degrees)*2))\n",
    "for ax in axs.flat:\n",
    "    ax.set_xlim([0, T+1])\n",
    "    ax.set_ylim([-0.6, 0.6])\n",
    "    ax.label_outer()\n",
    "\n",
    "mses=[]\n",
    "for degree in degrees:\n",
    "    X = get_predictors(degree, t)\n",
    "    model = LinearRegression(normalize=True)\n",
    "    model.fit(X, z)\n",
    "    z_hat = model.predict(X)\n",
    "    mse = np.mean((z_hat - z)**2)\n",
    "    print(\"Degree\", degree, \"MSE\", mse)\n",
    "    \n",
    "    betas = np.zeros((M*d, degree+1))\n",
    "    betas[:,0]= model.intercept_\n",
    "    betas[:,1:] = model.coef_\n",
    "\n",
    "    # Plot\n",
    "    row = 0\n",
    "    for index in range(0,16):\n",
    "        # Polynomial regression\n",
    "        w = np.flip(betas[index,:])\n",
    "        x = np.linspace(0, 10, 100)\n",
    "        z_hat = np.polyval(w, x)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        axs[degree-1][row].plot(x, z_hat, label=(str(degree)+\"-degree polynomial\"))\n",
    "        axs[degree-1][row].scatter(t, z[:,index])\n",
    "        axs[degree-1][0].set_title('degree =' + str(degree))\n",
    "        row += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2835c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 5\n",
    "X = get_predictors(degree, t)\n",
    "model = LinearRegression(normalize=True)\n",
    "model.fit(X, z)\n",
    "z_hat = model.predict(X)\n",
    "mse = np.mean((z_hat - z)**2)\n",
    "print(\"Regular polynomial regression MSE:\")\n",
    "print(mse)\n",
    "\n",
    "betas = np.zeros((M*d, degree+1))\n",
    "betas[:,0]= model.intercept_\n",
    "betas[:,1:] = model.coef_\n",
    "row_labels = [\"Value \"+str(i) for i in range(betas.shape[0])]\n",
    "column_labels = [\"Beta \"+str(i) for i in range(betas.shape[1])]\n",
    "df = pandas.DataFrame(betas, columns=column_labels, index=row_labels)\n",
    "pandas.options.display.float_format = '{:,.2g}'.format\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd12dc0",
   "metadata": {},
   "source": [
    "# LASSO Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72986d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-4\n",
    "lassoreg = Lasso(alpha=alpha,normalize=True, max_iter=100000)\n",
    "lassoreg.fit(X,z)\n",
    "z_hat = lassoreg.predict(X)\n",
    "\n",
    "print(\"LASSO polynomial regression MSE:\")\n",
    "print(mse)\n",
    "\n",
    "betas = np.zeros((M*d, degree+1))\n",
    "betas[:,0]= lassoreg.intercept_\n",
    "betas[:,1:] = lassoreg.coef_\n",
    "row_labels = [\"Value \"+str(i) for i in range(betas.shape[0])]\n",
    "column_labels = [\"Beta \"+str(i) for i in range(betas.shape[1])]\n",
    "df = pandas.DataFrame(betas, columns=column_labels, index=row_labels)\n",
    "pandas.options.display.float_format = '{:,.2g}'.format\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7400cd3a",
   "metadata": {},
   "source": [
    "## K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5280dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(1, T)\n",
    "alphas = [1e-15, 1e-10, 1e-5, 1e-4, 1e-3,1e-2,1e-1, 1, 5, 10]\n",
    "\n",
    "test_mse = []\n",
    "for train_index, test_index in kf.split(t, z):\n",
    "    split_mse = []\n",
    "    train_t, train_z = t[train_index], z[train_index]\n",
    "    test_t, test_z = t[test_index], z[test_index]\n",
    "    for degree in degrees:\n",
    "        split_degree_mse = []\n",
    "        for alpha in alphas:\n",
    "            train_X = get_predictors(degree, train_t)\n",
    "            test_X = get_predictors(degree, test_t)\n",
    "            k_lassoreg = Lasso(alpha=alpha,normalize=True, max_iter=100000)\n",
    "            k_lassoreg.fit(train_X, train_z)\n",
    "            pred_test_z = k_lassoreg.predict(test_X)\n",
    "            mse = np.mean((pred_test_z - test_z)**2)\n",
    "            split_degree_mse.append(mse)\n",
    "        split_mse.append(split_degree_mse)      \n",
    "    test_mse.append(split_mse)\n",
    "test_mse = np.mean(test_mse, axis=0)\n",
    "\n",
    "row_labels = [\"Degree \"+str(degrees[i]) for i in range(test_mse.shape[0])]\n",
    "column_labels = [\"Alpha \"+str(alphas[i]) for i in range(test_mse.shape[1])]\n",
    "df = pandas.DataFrame(test_mse, columns=column_labels, index=row_labels)\n",
    "pandas.options.display.float_format = '{:,.4g}'.format\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
